<!doctype html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Real-time Noise Suppression Demo</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      max-width: 800px;
      margin: 50px auto;
      padding: 20px;
    }

    .status {
      padding: 10px;
      margin: 10px 0;
      border-radius: 5px;
      background: #f0f0f0;
    }

    .status.active {
      background: #d4edda;
      color: #155724;
    }

    button {
      padding: 10px 20px;
      margin: 5px;
      font-size: 16px;
      cursor: pointer;
    }

    button:disabled {
      opacity: 0.5;
      cursor: not-allowed;
    }

    .audio-container {
      display: flex;
      gap: 20px;
      margin: 20px 0;
    }

    .audio-box {
      flex: 1;
      padding: 15px;
      border: 2px solid #ddd;
      border-radius: 5px;
    }

    .audio-box h3 {
      margin-top: 0;
    }

    .metrics {
      font-family: monospace;
      font-size: 12px;
      background: #f5f5f5;
      padding: 10px;
      border-radius: 3px;
      margin-top: 10px;
    }
  </style>
</head>

<body>
  <h1>üé§ Real-time Noise Suppression with DTLN</h1>

  <div class="status" id="status">
    Initializing DTLN module...
  </div>

  <div>
    <button id="btnStart">Start Real-time Processing</button>
    <button id="btnStop" disabled>Stop</button>
  </div>

  <div class="audio-container">
    <div class="audio-box">
      <h3>üîä Original Audio (with noise)</h3>
      <audio id="rawAudio" controls></audio>
      <p>Raw microphone input</p>
    </div>

    <div class="audio-box">
      <h3>‚ú® Processed Audio (clean)</h3>
      <audio id="cleanAudio" controls></audio>
      <p>Real-time noise suppressed</p>
    </div>
  </div>

  <div class="metrics" id="metrics">
    No metrics yet
  </div>

  <div style="margin-top: 30px; padding: 15px; background: #e7f3ff; border-radius: 5px;">
    <h3>üí° How to use:</h3>
    <ol>
      <li>Click "Start Real-time Processing"</li>
      <li>Allow microphone access</li>
      <li>Listen to both audio outputs - one with noise, one clean</li>
      <li>Make noise (tap desk, rustle paper) to hear the difference</li>
    </ol>
  </div>

  <script type="module">
    const SAMPLE_RATE = 16000;

    // UI elements
    const btnStart = document.getElementById('btnStart');
    const btnStop = document.getElementById('btnStop');
    const rawAudio = document.getElementById('rawAudio');
    const cleanAudio = document.getElementById('cleanAudio');
    const status = document.getElementById('status');
    const metricsDiv = document.getElementById('metrics');

    // Audio state
    let audioContext = null;
    let workletNode = null;
    let isProcessing = false;
    let rawStream = null;

    // Initialize
    async function initialize() {
      try {
        status.textContent = 'Loading DTLN WebAssembly module...';

        audioContext = new AudioContext({ sampleRate: SAMPLE_RATE });
        await audioContext.audioWorklet.addModule('audio-worklet.js');

        workletNode = new AudioWorkletNode(
          audioContext,
          'NoiseSuppressionWorker',
          {
            numberOfInputs: 1,
            numberOfOutputs: 1,
            outputChannelCount: [1],
            processorOptions: { disableMetrics: false }
          }
        );

        // Wait for WASM module to load
        await new Promise((resolve) => {
          workletNode.port.onmessage = (event) => {
            if (event.data === 'ready') {
              console.log('DTLN ready!');
              resolve();
            } else {
              // Display metrics
              updateMetrics(event.data);
            }
          };
        });

        status.textContent = '‚úÖ DTLN module ready! Click "Start" to begin.';
        status.classList.add('active');
        btnStart.disabled = false;
      } catch (error) {
        console.error('Initialization error:', error);
        status.textContent = '‚ùå Error: ' + error.message;
      }
    }

    // Start processing
    async function startProcessing() {
      try {
        if (audioContext.state === 'suspended') {
          await audioContext.resume();
        }

        // Get microphone access
        rawStream = await navigator.mediaDevices.getUserMedia({
          audio: {
            channelCount: 1,
            sampleRate: SAMPLE_RATE,
            echoCancellation: false,
            noiseSuppression: false,
            autoGainControl: false
          }
        });

        // Create audio graph
        const source = audioContext.createMediaStreamSource(rawStream);
        const rawDestination = audioContext.createMediaStreamDestination();
        const cleanDestination = audioContext.createMediaStreamDestination();

        // Connect: Mic -> raw output (bypass)
        source.connect(rawDestination);

        // Connect: Mic -> DTLN -> clean output
        source.connect(workletNode);
        workletNode.connect(cleanDestination);

        // Set audio elements
        rawAudio.srcObject = rawDestination.stream;
        cleanAudio.srcObject = cleanDestination.stream;

        // Auto-play
        rawAudio.play();
        cleanAudio.play();

        isProcessing = true;
        btnStart.disabled = true;
        btnStop.disabled = false;
        status.textContent = 'üéôÔ∏è Processing audio in real-time...';
        status.classList.add('active');

      } catch (error) {
        console.error('Error starting:', error);
        status.textContent = '‚ùå Error: ' + error.message;
        status.classList.remove('active');
      }
    }

    // Stop processing
    function stopProcessing() {
      if (rawStream) {
        rawStream.getTracks().forEach(track => track.stop());
        rawStream = null;
      }

      if (rawAudio.srcObject) {
        rawAudio.srcObject = null;
      }
      if (cleanAudio.srcObject) {
        cleanAudio.srcObject = null;
      }

      isProcessing = false;
      btnStart.disabled = false;
      btnStop.disabled = true;
      status.textContent = '‚è∏Ô∏è Stopped';
      status.classList.remove('active');
    }

    // Update metrics display
    function updateMetrics(data) {
      if (typeof data === 'object') {
        metricsDiv.innerHTML = `
          <strong>Real-time Metrics:</strong><br>
          Samples/sec: ${Math.round(data.avg_samples_processed)}<br>
          Input signal: ${data.avg_input_signal.toFixed(4)}<br>
          Output signal: ${data.avg_output_signal.toFixed(4)}<br>
          Enhancement: ${data.avg_signal_enhancement.toFixed(4)}<br>
          Suppression: ${data.avg_signal_suppression.toFixed(4)}
        `;
      }
    }

    // Event listeners
    btnStart.addEventListener('click', startProcessing);
    btnStop.addEventListener('click', stopProcessing);

    // Initialize on load
    initialize();
  </script>
</body>

</html>